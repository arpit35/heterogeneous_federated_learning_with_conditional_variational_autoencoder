{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44863bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.ml_models.utils import count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f8d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"model_architecture/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c15592",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246a03eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn Parameters: 6669258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpit\\AppData\\Local\\Temp\\ipykernel_24656\\1476775648.py:6: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(cnn, cnn_dummy_input, save_model_path + \"cnn.onnx\")\n"
     ]
    }
   ],
   "source": [
    "from src.ml_models.cnn import CNN\n",
    "\n",
    "cnn = CNN(\"cnn5\")\n",
    "\n",
    "cnn_dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(cnn, cnn_dummy_input, save_model_path + \"cnn.onnx\")\n",
    "\n",
    "print(\"Cnn Parameters:\", count_params(cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8f86a",
   "metadata": {},
   "source": [
    "# HFedCVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782691f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpit\\AppData\\Local\\Temp\\ipykernel_24656\\1873758387.py:15: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(vae, vae_dummy_input, save_model_path + \"vae.onnx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vae Parameters: 6646849\n"
     ]
    }
   ],
   "source": [
    "from src.ml_models.vae import VAE\n",
    "\n",
    "HFedCVAE = {\n",
    "    \"vae_parameters\": {\n",
    "        \"h_dim\": 248,\n",
    "        \"res_h_dim\": 60,\n",
    "        \"n_res_layers\": 3,\n",
    "        \"latent_dim\": 100,\n",
    "    }\n",
    "}\n",
    "\n",
    "vae = VAE(**HFedCVAE[\"vae_parameters\"])\n",
    "\n",
    "vae_dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(vae, vae_dummy_input, save_model_path + \"HFedCVAE_vae.onnx\")\n",
    "\n",
    "print(\"Vae Parameters:\", count_params(vae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9dc18",
   "metadata": {},
   "source": [
    "# HFedCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd857fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpit\\AppData\\Local\\Temp\\ipykernel_24656\\2062673423.py:25: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(generator, generator_dummy_input, save_model_path + \"generator1.onnx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Parameters: 1121316\n",
      "Discriminator Parameters: 99649\n",
      "Total GAN Parameters: 1220965\n"
     ]
    }
   ],
   "source": [
    "# from experments.gan import Discriminator, Generator\n",
    "from src.ml_models.discriminator import Discriminator\n",
    "from src.ml_models.generator import Generator\n",
    "\n",
    "HFedCGAN = {\n",
    "    \"generator_parameters\": {\n",
    "        \"n_block_layers\": 2,\n",
    "        \"h_dim\": 187,\n",
    "        \"latent_dim\": 100,\n",
    "        \"init_img_dim\": 7,\n",
    "    },\n",
    "    \"discriminator_parameters\": {\n",
    "        \"block_repeat\": 1,\n",
    "        \"n_block_layers\": 3,\n",
    "        \"h_dim\": 16,\n",
    "    },\n",
    "}\n",
    "\n",
    "generator = Generator(**HFedCGAN[\"generator_parameters\"])\n",
    "discriminator = Discriminator(**HFedCGAN[\"discriminator_parameters\"])\n",
    "# generator = Generator()\n",
    "# discriminator = Discriminator()\n",
    "\n",
    "generator_dummy_input = torch.randn(1, 100)\n",
    "torch.onnx.export(\n",
    "    generator, generator_dummy_input, save_model_path + \"HFedCGAN_generator.onnx\"\n",
    ")\n",
    "discriminator_dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(\n",
    "    discriminator,\n",
    "    discriminator_dummy_input,\n",
    "    save_model_path + \"HFedCGAN_discriminator.onnx\",\n",
    ")\n",
    "\n",
    "generator_parameters_count = count_params(generator)\n",
    "discriminator_parameters_count = count_params(discriminator)\n",
    "\n",
    "print(\"Generator Parameters:\", generator_parameters_count)\n",
    "print(\"Discriminator Parameters:\", discriminator_parameters_count)\n",
    "print(\n",
    "    \"Total GAN Parameters:\",\n",
    "    generator_parameters_count + discriminator_parameters_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d588c",
   "metadata": {},
   "source": [
    "# HFedCVAEGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml_models.vae import VAE\n",
    "from src.ml_models.discriminator import Discriminator\n",
    "\n",
    "HFedCVAEGAN = {\n",
    "    \"vae_parameters\": {\n",
    "        \"h_dim\": 248,\n",
    "        \"res_h_dim\": 60,\n",
    "        \"n_res_layers\": 3,\n",
    "        \"latent_dim\": 100,\n",
    "    },\n",
    "    \"discriminator_parameters\": {\n",
    "        \"block_repeat\": 1,\n",
    "        \"n_block_layers\": 3,\n",
    "        \"h_dim\": 16,\n",
    "    },\n",
    "}\n",
    "\n",
    "vae = VAE(**HFedCVAEGAN[\"vae_parameters\"])\n",
    "discriminator = Discriminator(**HFedCVAEGAN[\"discriminator_parameters\"])\n",
    "\n",
    "vae_dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(vae, vae_dummy_input, save_model_path + \"HFedCVAEGAN_vae.onnx\")\n",
    "discriminator_dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(\n",
    "    discriminator,\n",
    "    discriminator_dummy_input,\n",
    "    save_model_path + \"HFedCVAEGAN_discriminator.onnx\",\n",
    ")\n",
    "\n",
    "vae_parameters_count = count_params(vae)\n",
    "discriminator_parameters_count = count_params(discriminator)\n",
    "\n",
    "print(\"Vae Parameters:\", vae_parameters_count)\n",
    "print(\"Discriminator Parameters:\", discriminator_parameters_count)\n",
    "print(\n",
    "    \"Total VAE-GAN Parameters:\",\n",
    "    vae_parameters_count + discriminator_parameters_count,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b6c9f",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429edf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scripts.helper import save_metadata\n",
    "\n",
    "save_metadata(\n",
    "    {\n",
    "        \"HFedCVAE\": HFedCVAE,\n",
    "        \"HFedCGAN\": HFedCGAN,\n",
    "        \"HFedCVAEGAN\": HFedCVAEGAN,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
